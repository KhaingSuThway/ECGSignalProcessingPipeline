{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from read_record import Record,RecordReader,plot_signal_with_annotation\n",
    "from scanning_window import scan_record\n",
    "from collections import Counter\n",
    "from transform_image import get_combined_beat_image\n",
    "\n",
    "from neurokit2 import ecg_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=\"D:/CPSC2021/Training_set_II\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"data_89_13\"\n",
    "reading_record=RecordReader.read(folder_path,file_name,0,0,None)\n",
    "reading_record._Record__label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(reading_record._Record__aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_record.get_afib_interval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_record.get_nsr_interval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_record.plot_signal_with_annotation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scan=scan_record(reading_record,window_width=30)\n",
    "test_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(test_scan.true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(list(              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal=np.array(list(test_scan.iloc[431][0:5999]))\n",
    "clean_signal=nk.ecg_clean(signal,200)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(clean_signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal_with_annotation(clean_signal,\n",
    "                            test_scan.iloc[431]['beat_annotation_symbols'],\n",
    "                             test_scan.iloc[431]['annotated_samples'],200,\n",
    "                             'r.', figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter the DataFrame for rows where 'true_class' is 'pac'\n",
    "# pac_df = test_scan[test_scan['true_class'] == 'PAC']\n",
    "\n",
    "# # Save the filtered DataFrame to a CSV file\n",
    "# pac_df.to_csv('data_104_21_pac.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select rows from 30 to 60 (note that the end index is exclusive)\n",
    "# selected_rows = test_scan.iloc[ 6:775]\n",
    "# # Save the selected rows to a CSV file\n",
    "# selected_rows.to_csv('data_89_13_pac.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_combined_beat_image(signal=clean_signal,\n",
    "                        bpm=test_scan.iloc[431]['avg_heart_rate'],\n",
    "                        voltage_range=[-3, 3], \n",
    "                        folder_name='test', img_name='Test_beat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_files=[file[:-4] for file in os.listdir(folder_path) if file.endswith('atr')]\n",
    "#record_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_records(folder_path, type=None):\n",
    "    \"\"\"\n",
    "    Process all ECG records in a specified folder, segment them, filter based on a specified type,\n",
    "    and generate corresponding CSV files and combined beat images.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): The path to the folder containing the ECG record files.\n",
    "    - type (str): The type of segments to filter (e.g., 'Pure_NSR'). If None, no filtering is applied.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the specified folder_path does not exist or if an invalid type is provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the CSV folder if it doesn't exist\n",
    "    csv_folder = f'{type}_data'\n",
    "    if not os.path.exists(csv_folder):\n",
    "        os.makedirs(csv_folder)\n",
    "\n",
    "    # Loop through each file in record_files\n",
    "    for file in record_files:\n",
    "        print(f'{file}')\n",
    "        csv_file_path = os.path.join(csv_folder, f\"{file}_{type}.csv\")\n",
    "        \n",
    "        # Check if the CSV file already exists\n",
    "        if os.path.exists(csv_file_path):\n",
    "            print(f\"{file}_{type}.csv file is already created in {csv_folder}\")\n",
    "        else:        \n",
    "            # Read the ECG record\n",
    "            record = RecordReader.read(folder_path, file, 0, 0, None)\n",
    "            if record._Record__label == 'non atrial fibrillation':\n",
    "                # Segment the ECG record\n",
    "                segments = scan_record(record, window_width=30)\n",
    "                # Filter segments based on the specified type (e.g., 'Pure_NSR')\n",
    "                buffer_dataframe = segments[segments['true_class'] == f'{type}']\n",
    "                \n",
    "                # Save filtered data to CSV\n",
    "                buffer_dataframe.to_csv(csv_file_path, index=False)\n",
    "                \n",
    "                #print(f\"CSV file created: {csv_file_path}\")\n",
    "\n",
    "                # Process each segment\n",
    "                for i in range(len(buffer_dataframe)):\n",
    "                    signal = np.array(list(buffer_dataframe.iloc[i][0:5999]))\n",
    "                    clean_signal = nk.ecg_clean(signal, 200)\n",
    "                    # Generate a combined beat image\n",
    "                    get_combined_beat_image(signal=clean_signal,\n",
    "                                            bpm=buffer_dataframe.iloc[i]['avg_heart_rate'],\n",
    "                                            voltage_range=[-3, 3],\n",
    "                                            folder_name=f'{type}_image', img_name=f'{file}_{i}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_100_1\n",
      "data_100_1_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_10\n",
      "data_100_10_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_11\n",
      "data_100_11_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_12\n",
      "data_100_12_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_13\n",
      "data_100_13_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_2\n",
      "data_100_2_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_3\n",
      "data_100_3_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_4\n",
      "data_100_4_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_5\n",
      "data_100_5_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_6\n",
      "data_100_6_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_7\n",
      "data_100_7_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_8\n",
      "data_100_8_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_100_9\n",
      "data_100_9_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_101_1\n",
      "data_101_1_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_101_10\n",
      "data_101_10_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_101_2\n",
      "data_101_2_Pure_NSR.csv file is already created in Pure_NSR_data\n",
      "data_101_3\n",
      "data_101_4\n",
      "data_101_5\n",
      "data_101_6\n",
      "data_101_7\n",
      "data_101_8\n",
      "data_101_9\n",
      "data_102_1\n",
      "data_102_2\n",
      "data_102_3\n",
      "data_102_4\n",
      "data_102_5\n",
      "data_102_6\n",
      "data_102_7\n",
      "data_102_8\n",
      "data_103_1\n",
      "There are 353 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_103_1_Pure_NSR.csv\n",
      "data_103_2\n",
      "There are 177 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_103_2_Pure_NSR.csv\n",
      "data_103_3\n",
      "There are 244 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_103_3_Pure_NSR.csv\n",
      "data_104_1\n",
      "data_104_10\n",
      "There are 316 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_104_10_Pure_NSR.csv\n",
      "data_104_11\n",
      "data_104_12\n",
      "data_104_13\n",
      "data_104_14\n",
      "data_104_15\n",
      "There are 253 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_104_15_Pure_NSR.csv\n",
      "data_104_16\n",
      "data_104_17\n",
      "data_104_18\n",
      "data_104_19\n",
      "data_104_2\n",
      "data_104_20\n",
      "data_104_21\n",
      "There are 771 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_104_21_Pure_NSR.csv\n",
      "data_104_22\n",
      "data_104_23\n",
      "There are 246 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_104_23_Pure_NSR.csv\n",
      "data_104_24\n",
      "data_104_25\n",
      "data_104_26\n",
      "data_104_27\n",
      "data_104_28\n",
      "data_104_3\n",
      "data_104_4\n",
      "data_104_5\n",
      "data_104_6\n",
      "data_104_7\n",
      "data_104_8\n",
      "data_104_9\n",
      "There are 454 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_104_9_Pure_NSR.csv\n",
      "data_54_1\n",
      "data_54_2\n",
      "data_54_3\n",
      "data_54_4\n",
      "data_54_5\n",
      "data_54_6\n",
      "data_54_7\n",
      "data_55_1\n",
      "There are 3013 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_55_1_Pure_NSR.csv\n",
      "data_55_10\n",
      "There are 2020 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_55_10_Pure_NSR.csv\n",
      "data_55_2\n",
      "There are 1507 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_55_2_Pure_NSR.csv\n",
      "data_55_3\n",
      "There are 1710 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_55_3_Pure_NSR.csv\n",
      "data_55_4\n",
      "There are 1244 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_55_4_Pure_NSR.csv\n",
      "data_55_5\n",
      "There are 1523 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_55_5_Pure_NSR.csv\n",
      "data_55_6\n",
      "There are 1270 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_55_6_Pure_NSR.csv\n",
      "data_55_7\n",
      "There are 2123 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_55_7_Pure_NSR.csv\n",
      "data_55_8\n",
      "There are 1827 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_55_8_Pure_NSR.csv\n",
      "data_55_9\n",
      "There are 1900 segments in the record.\n",
      "CSV file created: Pure_NSR_data\\data_55_9_Pure_NSR.csv\n"
     ]
    }
   ],
   "source": [
    "process_all_records(folder_path,'Pure_NSR')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
